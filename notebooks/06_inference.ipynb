{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train final model on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pathlib import PurePath\n",
    "\n",
    "PROCESSED_DIR = PurePath(\"../topolearn/processed_data\")\n",
    "df = pd.read_csv(PROCESSED_DIR / \"results.csv\")\n",
    "\n",
    "# Features used in the final model\n",
    "lifetime_cols = [col for col in df.columns if (\"life\" in col) and (not \"train\" in col)]\n",
    "topo_props = [\"b_0\", \"b_1\", \"b_0_norm\", \"b_1_norm\", \"ph_entr_0\", \"ph_entr_1\"]\n",
    "ph_features = topo_props + lifetime_cols\n",
    "target = \"Relative RMSE\"\n",
    "\n",
    "X, y = df[ph_features], df[target]\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Save for inference\n",
    "with open('topolearn.pkl','wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ripser import ripser\n",
    "from gtda.diagrams import PersistenceEntropy\n",
    "\n",
    "class TopoLearn():\n",
    "    def __init__(self, model_path=\"topolearn.pkl\") -> None:\n",
    "        \"\"\"Class to compute the TopoLearn score using persistent homology.\n",
    "\n",
    "        Args:\n",
    "            X (numpy array): The numeric representation of a dataset.\n",
    "            sim_metric (string): Distance metric used by ripser for PH computation.\n",
    "        \"\"\"\n",
    "        with open(model_path, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "            self.features = ['b_0','b_1','b_0_norm','b_1_norm','ph_entr_0','ph_entr_1','lifetimes_min_0',\n",
    "                             'norm_lifetimes_min_0','lifetimes_max_0','norm_lifetimes_max_0','lifetimes_mean_0',\n",
    "                             'norm_lifetimes_mean_0','lifetimes_var_0','norm_lifetimes_var_0','lifetimes_sum_0',\n",
    "                             'norm_lifetimes_sum_0','midlifes_min_0','norm_midlifes_min_0','midlifes_max_0',\n",
    "                             'norm_midlifes_max_0','midlifes_mean_0','norm_midlifes_mean_0','midlifes_var_0',\n",
    "                             'norm_midlifes_var_0','midlifes_sum_0','norm_midlifes_sum_0','lifetimes_min_1',\n",
    "                             'norm_lifetimes_min_1','lifetimes_max_1','norm_lifetimes_max_1','lifetimes_mean_1',\n",
    "                             'norm_lifetimes_mean_1','lifetimes_var_1','norm_lifetimes_var_1','lifetimes_sum_1',\n",
    "                             'norm_lifetimes_sum_1','midlifes_min_1','norm_midlifes_min_1','midlifes_max_1',\n",
    "                             'norm_midlifes_max_1','midlifes_mean_1','norm_midlifes_mean_1','midlifes_var_1',\n",
    "                             'norm_midlifes_var_1','midlifes_sum_1','norm_midlifes_sum_1']\n",
    "\n",
    "    def _compute_lifetime_stats(self, dgm, h_dim, suffix=\"\"):\n",
    "        # Normal persistence lifetimes\n",
    "        dgm = dgm[~np.isinf(dgm).any(1)]\n",
    "        descriptors = {}\n",
    "        aggs = [np.min, np.max, np.mean, np.var, np.sum]\n",
    "        \n",
    "        # Lifetime descriptors\n",
    "        lifetimes = dgm[:, 1] - dgm[:, 0]\n",
    "        if lifetimes.shape[0] > 0:\n",
    "            norm_lifetimes = lifetimes / lifetimes.sum()\n",
    "            for agg in aggs:\n",
    "                descriptors[f\"lifetimes_{agg.__name__}_{h_dim}{suffix}\"] = agg(lifetimes)\n",
    "                descriptors[f\"norm_lifetimes_{agg.__name__}_{h_dim}{suffix}\"] = agg(norm_lifetimes)\n",
    "            \n",
    "        else:\n",
    "            for agg in aggs:\n",
    "                descriptors[f\"lifetimes_{agg.__name__}_{h_dim}{suffix}\"] = np.nan\n",
    "                descriptors[f\"norm_lifetimes_{agg.__name__}_{h_dim}{suffix}\"] = np.nan\n",
    "\n",
    "        # Midlife descriptors\n",
    "        midlifes = (dgm[:, 1] + dgm[:, 0]) / 2\n",
    "        if midlifes.shape[0] > 0:\n",
    "            norm_midlifes = midlifes / midlifes.sum()\n",
    "            for agg in aggs:\n",
    "                descriptors[f\"midlifes_{agg.__name__}_{h_dim}{suffix}\"] = agg(midlifes)\n",
    "                descriptors[f\"norm_midlifes_{agg.__name__}_{h_dim}{suffix}\"] = agg(norm_midlifes)\n",
    "            \n",
    "        else:\n",
    "            for agg in aggs:\n",
    "                descriptors[f\"midlifes_{agg.__name__}_{h_dim}{suffix}\"] = np.nan\n",
    "                descriptors[f\"norm_midlifes_{agg.__name__}_{h_dim}{suffix}\"] = np.nan        \n",
    "        return descriptors\n",
    "\n",
    "    def _compute_betti(self, dgm):\n",
    "        b = dgm.shape[0]\n",
    "        return b\n",
    "\n",
    "    def _compute_betti_norm(self, X, dgm):\n",
    "        b_norm = dgm.shape[0] / X.shape[0]\n",
    "        return b_norm\n",
    "\n",
    "    def _compute_persistence_entropy(self, dgms, idx=0):\n",
    "        # Align the format for ripser with giotto-tda\n",
    "        q_pad = np.concatenate([dgms[idx], np.full((dgms[idx].shape[0], 1), idx)], axis=1)\n",
    "        dgms_giotto = np.expand_dims(q_pad, 0)\n",
    "        PE = PersistenceEntropy(n_jobs=-1)\n",
    "        return PE.fit_transform(dgms_giotto)\n",
    "    \n",
    "    def _compute_ph_features(self, X, dgms):\n",
    "        features = {}\n",
    "        features[\"b_0\"] = self._compute_betti(dgms[0])\n",
    "        features[\"b_1\"] = self._compute_betti(dgms[1])\n",
    "        features[\"b_0_norm\"] = self._compute_betti_norm(X, dgms[0])\n",
    "        features[\"b_1_norm\"] = self._compute_betti_norm(X, dgms[1])\n",
    "\n",
    "        if len(dgms[0]) > 0:\n",
    "            ph_entr_0 = self._compute_persistence_entropy(dgms, idx=0)[0][0]\n",
    "        else:\n",
    "            ph_entr_0 = np.nan     \n",
    "        if len(dgms[1]) > 0:\n",
    "            ph_entr_1 = self._compute_persistence_entropy(dgms, idx=1)[0][0]\n",
    "        else:\n",
    "            ph_entr_1 = np.nan   \n",
    "\n",
    "        features[\"ph_entr_0\"] = ph_entr_0\n",
    "        features[\"ph_entr_1\"] = ph_entr_1\n",
    "        features = features | self._compute_lifetime_stats(dgms[0], h_dim=0)\n",
    "        features = features | self._compute_lifetime_stats(dgms[1], h_dim=1)\n",
    "        return features\n",
    "\n",
    "    def compute_score(self, X, sim_metric,):\n",
    "        dgms = ripser(X, metric=sim_metric)['dgms'] \n",
    "        features = self._compute_ph_features(X, dgms)\n",
    "        assert all([i == j for i, j in zip(self.features, features)])\n",
    "        feature_vector = np.array(list(features.values())).reshape(1, -1)\n",
    "        return self.model.predict(feature_vector)\n",
    "\n",
    "tl = TopoLearn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on new datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5690018080283844"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from topolearn import topolearn\n",
    "\n",
    "# Prepare data\n",
    "X = np.random.normal(3, 1, size=(1000, 128))\n",
    "sim_metric = \"euclidean\"\n",
    "\n",
    "# Compute score\n",
    "tl = topolearn.TopoLearn()\n",
    "tl.compute_score(X, sim_metric=sim_metric, clip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
